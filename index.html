<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>GESCAM : A Dataset and Method on Gaze Estimation for Classroom Attention Measurement</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">GESCAM : A Dataset and Method on Gaze Estimation for Classroom Attention Measurement</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Athul M. Mathew</a>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Arshad Ali Khan</a>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Thariq Khalid</a>,</span>
                    <span class="author-block">
                    <a href="Fourth AUTHOR PERSONAL LINK" target="_blank">Riad Souissi</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Elm Company<br>CVPR GAZE 2024</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/Classroom_06_video_01_final2 - Trim.mp4"
        type="video/mp4">
      </video>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Human gaze provides crucial insights into individual attention during social or educational interactions. Attention systems often rely on head and facial features to predict gaze direction, but reliable gaze target detection (GTD) requires rich contextual cues. These cues inform the system about an individual's position within a scene and the surrounding objects they might be interacting with. Our paper proposes attention measurement using GTD in educational classrooms, leveraging a synthetic dataset called GESCAM (Gaze Estimation based Synthetic Classroom Attention Measurement). This dataset was meticulously generated using 3D modelling, animation, simulation, and rendering techniques comprising 60,000 images with 650,000 instances of individuals (students, teachers) engaged in various activities, including looking at blackboard, notebooks, mobile phones etc. Our novel network trained on GESCAM proficiently identifies gaze fixations within complex classroom scenes, offering insights into human attention in classrooms across diverse contexts.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/classroom11_cam1.PNG" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          RGB image of classroom
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/classroom11_cam1_depth.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Depth map for each corresponding RGB image
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/classroom11_cam1_with_bounding_boxes.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Annotation of bounding boxes and labels for people and various objects within the scene
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/classroom11_cam1_with_object_mask.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Masks highlighting individual objects for precise identification
      </h2>
    </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/classroom11_cam1_with_gaze_lines.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Gaze lines indicating points of interests within the scene
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->



<!--Dataset -->
  <section class="section" id="Dataset">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
        <p>
        Please request full access to GESCAM dataset here
        </p>
    </div>
</section>
<!--End BibTex citation -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
        <p>
        If you find this work useful, please cite:
        </p>
          <pre><code>@inproceedings{athul2024gescam,
  title={GESCAM : A Dataset and Method on Gaze Estimation for Classroom Attention Measurement},
  author={Mathew, Athul and Khan, Arshad and Khalid, Thariq and Souissi, Riad},
  booktitle = {CVPR Workshops (CVPRW)},
  year={2024},
  pubstate={published},
  tppubtype={inproceedings}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
